# 로드밸런싱
작성일 : 2024-01-02

작성목적 : AWS 로드 밸런스 사용을 위한 원리 파악

## 개요
추론 RESTful API 서버를 개발하면서 해당 서버를 GPU 3대에 분리하여 도커 컨테이너로 분산하여 추론 시간을 줄이고 사용자 딜레이를 최소화 하려고 한다.
이떄 3대의 GPU를 각각 EC2 인스턴스에 할당해주고 로드밸런서를 통해서 해당 부하를 나누어 줄것이다.
로드 밸런싱이라는 것이 각각 리퀘스트가 몰리는 상황에서 집중된 리퀘스트를 분산하는 것이라고만 알고 있는데 정확하게 개념을 집고 해당 상황을 넘어가보자

## 로드밸런싱(Load Balnancing)
둘 혹은 셋 이상의 중앙처리 장치 혹은 저장장치와 같은 컴퓨팅 리소스에게 작업(work)
를 나누는 것, 즉 부하(Load)를 나누는 것을 의미한다.
이를 통해서 가용성 및 응답시간을 최적화 한다.

>회사를 예시를 통하자만 하나의 프로젝트 규모가 커져서 혼자 쳐내던 업무 분장을 위해서 계약직 직원을 들인다 이런 느낌이다.

![](https://velog.velcdn.com/images/kimdodo/post/920dc10b-1e14-4b62-b54d-a740b90da6b9/image.png)

로드 밸런스를 보여주는 예시 그림이다.
로드 밸런스는 클라이언트의 요청 및 네트워크 트래픽이 집중되는 서버들(Server Pool/ Server Farm) 또는 네트워크 허브 사이에 위치해서 특정 서버 또는 네트워크 허브에 부하가 집중되지 않게 트래픽을 분산하는 것

### 기본 기능
1. #### Health Check (상태 확인)
- 서버들에 대한 주기적인 헬스 체크를 통해서 서버 장애 여부를 파악
정상 동작 서버에만 트래픽 보냄
- L3 체크 : ICMP를 이용해서 서버의 **IP 주소가 통신 가능**인지 확인
- L4 체크 : TCP는** 3Way-handshak**e 기반 통신, 이 특성을 바탕으로 각 포트 상태 체크
- L7 체크 : 어플리케이션 계층에서 체크를 수행, **실제 웹 페이지 통신** 시도

2. #### Tunneling(터널링)
- 데이터 스트림을 인터넷 상에서 가상의 파이프를 통해 전달시키는 기술
- 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화 해제

3. #### NAT(Netwrok Address Translation)
- 내부 네트워크의 사설 IP 주소, 로드밸런서 외부의 공인 IP 주소간의 변환 역할
- 로드 밸런싱 관점에서는 여러개의 호스트가 하나의 공인 주소 IP 를 통해서 접속하는 것이 목표
- SNAT(Source Network Address Translation)
내부에서 외부로 나가는 트래픽 (내부 사설 IP --> 외부 공인 IP)
- DNAT(Source Network Address Translation)
외부에서 내부로 트래픽(외부 공인 IP ----> 내부 사설 IP)

4. #### DSR(Destination Network Address Translation)
- 서버에서 클라이언트로 트래픽이 되돌아가는 경우, 목적지를 클라이언트로 설정한 다음, 네트워크 장비나 로드밸런서를 거치지 않고 클라이언트를 찾아감
- 로드밸런서의 부하 감소

## 로드밸런싱 알고리즘
1. #### RR(Round Robin)
서버에 들어온 요청 순서대로 돌아가며 배정
클라이언트의 요청대로 순서 분배, 서버들이 동일 스펙 및 연결이 오래 지속되지 않는 경우 적합

2. #### 가중 라운드로빈 방식(Weighted Round Robin)
각 서버마다 가중치를 가지고 가중치가 높은 서버에 클라이언트 우선 배치
성능이 높은 서버가 가중치가 높겠다

3. #### IP 해시 방식
클라이언트 IP 주소를 특정 서버로 매핑하여 요청 처리
사용자 IP를 해싱하여 부하 분산 사용자가 항상 동일 서버로 연결
> 아직 GPU 3대에 분산을 어떻게 할지 모르지만 사이트별로 나눈다면 유용할것으로 보임

4. #### 최소 연결 방식
리퀘스트가 들어온 시점에서 가장 적은 세션 상태를 보이는 서버에 우선 할당
세션이 길어지거나, 서버에 분배된 트래픽이 일정하지 않은 경우

5. #### 최소 응답시간 방식
서버의 현재 연결 상태 및 응답시간을 고려, 가장 짧은 응답시간을 보내느 서버로 트래픽
각 서버들의 가용한 리소스와 성능, 처리중인 데이터양이 상이할 경우
> 3대가 모두 동일한 처리를 하는 경우에는 좋음

6. #### 대역폭 방식
서버들과의 대역폭을 고려하는 방식

## L4 / L7
대부분의 로드밸런서는 L4 또는 L7 로드밸런서를 사용

### 1. L4
4계층 즉 네트워크 계층(IP)나 3계층(TCP/UDP) 정보를 바탕으로 로드를 분산하는 방식
IP주소, 포트번호, MAC 주소 등 전송 프로토콜에 따라서 트래픽을 분산한다.

![](https://velog.velcdn.com/images/kimdodo/post/ea7e9506-284f-49b1-a5c3-92a7d206895b/image.png)

#### 👍장점
>👉 패킷의 내용을 확인하지 않고 로드 분산(속도 효율 높음)
👉 데이터의 내용을 복호화할 필요가 없기에 안전
👉 L7 로드밸런서 보다 가격이 저렴

#### 👎단점
> 👉 패킷 내용을 모르기 때문에 섬세한 라우팅 불가
👉 사용자의 IP가 수시로 바뀌면 연속적 서비스 불가

### 1. L7
네트워크 7계층 즉 어플리케이션 계층(HTTP,FTP,SMTP) 에서 로드 분산
HTTP헤더나 쿠키 같은 사용자 요청 기준 분리

![](https://velog.velcdn.com/images/kimdodo/post/1487e35e-69f5-4141-8bed-d0d5bc75d3fe/image.png)

L4에서 더 나아가 패킷 내용을 확인하고 내용에 따라서 로드를 특성 서버에 분배
패턴을 파악한 바이러스 탐지 등 보안성이 좋음

- URL 스위칭
특정 하위 URL들은 특성 서버로 처리하는 방식
- 컨텍스트 스위칭
클라이언트가 요청한 특정 리소스에 대해 특정 서버로 연결
이미지나 동영상의 확장자를 참조해 해당 이미지 서버로 연결 한다던가
- 쿠키 지속성
쿠키 정보를 바탕으로 클라이언트가 연결했었던 동일한 서버에 계속 할당
사설 네트워크에 있던 클라이언트의 IP주소가 공인 IP 주소로 치환 전송

#### 👍장점
>👉 상위 계층에서 로드 분산 --> 섬세한 라우팅
👉 캐싱 기능 제공
👉 비정상 트래픽 필터링으로 보안 높음

#### 👎단점
> 👉 가격이 높음
👉 패킷의 내용을 복호화 ---> 자원 비용 증가
👉 인증서를 공유해야해서 공격자가 로드밸런서를 통한 클라이언트 데이터에 접근 가능

## 마무리
로드 밸런서를 통해서 어떻게 트래픽을 처리하는 방식이 있는지 알아봤다.
나는 AWS의 로드밸런서의 어플리케이션 밸런서와 네트워크 밸런서를 쓰려고 하는데 이 정리본에 기반하여 AWS 로드밸런서를 리뷰하고 현재 아키텍처에 적합한 로드 밸런스를 한번 알아보겠다.

